{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\Desktop\\STNN-main\\model\\driver.py:65\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39m###### scale #####\u001b[39;00m\n\u001b[0;32m     64\u001b[0m Xmax, Xmin \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(X), np\u001b[39m.\u001b[39mmin(X)\n\u001b[1;32m---> 65\u001b[0m X \u001b[39m=\u001b[39m ((X\u001b[39m-\u001b[39;49mXmin)\u001b[39m/\u001b[39m(Xmax\u001b[39m-\u001b[39mXmin)\u001b[39m+\u001b[39m\u001b[39m0.01\u001b[39m)\u001b[39m*\u001b[39m\u001b[39m0.9\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39m##### split into train and test set #####\u001b[39;00m\n\u001b[0;32m     69\u001b[0m Xtrain \u001b[39m=\u001b[39m X[\u001b[39m0\u001b[39m:t\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m\u001b[39m*\u001b[39margs\u001b[39m.\u001b[39mdy\u001b[39m+\u001b[39m\u001b[39m2\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "run driver.py --dataset ../data/solar.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43.240337 48.40549  54.660973 60.119392 62.34319  61.43646  61.1941\n",
      " 61.504158 60.95283  60.088753 60.962555 61.470642 61.692547 62.94248\n",
      " 64.23886  65.40444  66.830505 66.18614  62.31111 ]\n"
     ]
    }
   ],
   "source": [
    "run driver.py --dataset ../data/TS.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.10196036091815491"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE\n",
    "Pearson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Setup ****\n",
      "Total params: 0.57k\n",
      "************\n",
      "AAL(\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "    (linear): Linear(in_features=1, out_features=1, bias=True)\n",
      "    (attentionLayer): AttentionLayer(\n",
      "      (Wq): Linear(in_features=1, out_features=6, bias=False)\n",
      "      (Wk): Linear(in_features=1, out_features=6, bias=False)\n",
      "      (Wv): Linear(in_features=1, out_features=1, bias=False)\n",
      "      (attention): Attention(\n",
      "        (dropout): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((1, 1), eps=1e-05, elementwise_affine=True)\n",
      "    (f): ELU(alpha=1.0)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "    (linear1): Linear(in_features=15, out_features=15, bias=True)\n",
      "    (attentionLayer): AttentionLayer(\n",
      "      (Wq): Linear(in_features=1, out_features=6, bias=False)\n",
      "      (Wk): Linear(in_features=1, out_features=6, bias=False)\n",
      "      (Wv): Linear(in_features=1, out_features=1, bias=False)\n",
      "      (attention): Attention(\n",
      "        (dropout): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((15, 1), eps=1e-05, elementwise_affine=True)\n",
      "    (EDAttention): Attention(\n",
      "      (dropout): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "    (norm2): LayerNorm((15, 1), eps=1e-05, elementwise_affine=True)\n",
      "    (linear2): Linear(in_features=15, out_features=15, bias=True)\n",
      "    (f): ELU(alpha=1.0)\n",
      "  )\n",
      ")\n",
      "********** Epoche 1 **********\n",
      "loss :  0.013646422885358334\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\OneDrive\\Escritorio\\STNN-main\\model\\driver.py:108\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[0;32m    105\u001b[0m \u001b[39m#==============================================================================\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39m#==============================================================================\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m model \u001b[39m=\u001b[39m train(model, train_loader,lr\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mlr, learning_rate_change\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mlr_decay, epoch_update\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mlr_update,\n\u001b[0;32m    109\u001b[0m             weight_decay\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mwd, num_epochs \u001b[39m=\u001b[39;49m args\u001b[39m.\u001b[39;49mepochs, gradclip\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mgradclip)\n\u001b[0;32m    110\u001b[0m \u001b[39m#******************************************************************************\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39m# Prediction\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39m#******************************************************************************\u001b[39;00m\n\u001b[0;32m    113\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\OneDrive\\Escritorio\\STNN-main\\model\\train.py:30\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, lr, epoch_update, learning_rate_change, weight_decay, num_epochs, gradclip)\u001b[0m\n\u001b[0;32m     28\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     29\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> 30\u001b[0m     torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49mclip_grad_norm_(model\u001b[39m.\u001b[39;49mparameters(), gradclip)\n\u001b[0;32m     31\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     32\u001b[0m \u001b[39m# schedule learning rate decay    \u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\utils\\clip_grad.py:55\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite, foreach)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m ((device, _), [grads]) \u001b[39min\u001b[39;00m grouped_grads\u001b[39m.\u001b[39mitems():\n\u001b[0;32m     54\u001b[0m     \u001b[39mif\u001b[39;00m (foreach \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m foreach) \u001b[39mand\u001b[39;00m _has_foreach_support(grads, device\u001b[39m=\u001b[39mdevice):\n\u001b[1;32m---> 55\u001b[0m         norms\u001b[39m.\u001b[39mextend(torch\u001b[39m.\u001b[39;49m_foreach_norm(grads, norm_type))\n\u001b[0;32m     56\u001b[0m     \u001b[39melif\u001b[39;00m foreach:\n\u001b[0;32m     57\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mforeach=True was passed, but can\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mt use the foreach API on \u001b[39m\u001b[39m{\u001b[39;00mdevice\u001b[39m.\u001b[39mtype\u001b[39m}\u001b[39;00m\u001b[39m tensors\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run driver.py --dataset ../basic_series/raw_12.csv --lr 0.2 --lr_decay 0.2 --epochs 400 --dy 15 --noise 0.05 --length 6 --batch 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Setup ****\n",
      "Total params: 1.49k\n",
      "************\n",
      "AAL(\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "    (linear): Linear(in_features=22, out_features=22, bias=True)\n",
      "    (attentionLayer): AttentionLayer(\n",
      "      (Wq): Linear(in_features=1, out_features=4, bias=False)\n",
      "      (Wk): Linear(in_features=1, out_features=4, bias=False)\n",
      "      (Wv): Linear(in_features=1, out_features=1, bias=False)\n",
      "      (attention): Attention(\n",
      "        (dropout): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((22, 1), eps=1e-05, elementwise_affine=True)\n",
      "    (f): ELU(alpha=1.0)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "    (linear1): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (attentionLayer): AttentionLayer(\n",
      "      (Wq): Linear(in_features=1, out_features=4, bias=False)\n",
      "      (Wk): Linear(in_features=1, out_features=4, bias=False)\n",
      "      (Wv): Linear(in_features=1, out_features=1, bias=False)\n",
      "      (attention): Attention(\n",
      "        (dropout): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((20, 1), eps=1e-05, elementwise_affine=True)\n",
      "    (EDAttention): Attention(\n",
      "      (dropout): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "    (norm2): LayerNorm((20, 1), eps=1e-05, elementwise_affine=True)\n",
      "    (linear2): Linear(in_features=20, out_features=20, bias=True)\n",
      "    (f): ELU(alpha=1.0)\n",
      "  )\n",
      ")\n",
      "********** Epoche 1 **********\n",
      "loss :  0.03955557569861412\n",
      "********** Epoche 101 **********\n",
      "loss :  0.00033879050170071423\n",
      "********** Epoche 201 **********\n",
      "loss :  0.0003401091380510479\n",
      "********** Epoche 301 **********\n",
      "loss :  0.00043929152889177203\n",
      "0.9361840383011443\n"
     ]
    }
   ],
   "source": [
    "run driver.py --dataset ../data/gene.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\Desktop\\STNN-main\\model\\driver.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtrain\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcopy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:66\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m _docstring\n\u001b[0;32m     64\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     65\u001b[0m     FigureCanvasBase, FigureManagerBase, MouseButton)\n\u001b[1;32m---> 66\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfigure\u001b[39;00m \u001b[39mimport\u001b[39;00m Figure, FigureBase, figaspect\n\u001b[0;32m     67\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgridspec\u001b[39;00m \u001b[39mimport\u001b[39;00m GridSpec, SubplotSpec\n\u001b[0;32m     68\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m rcsetup, rcParamsDefault, rcParamsOrig\n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\figure.py:43\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmpl\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m _blocking_input, backend_bases, _docstring, projections\n\u001b[0;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39martist\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     45\u001b[0m     Artist, allow_rasterization, _finalize_rasterization)\n\u001b[0;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     47\u001b[0m     DrawEvent, FigureCanvasBase, NonGuiException, MouseButton, _get_renderer)\n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\projections\\__init__.py:57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m axes, _docstring\n\u001b[0;32m     56\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgeo\u001b[39;00m \u001b[39mimport\u001b[39;00m AitoffAxes, HammerAxes, LambertAxes, MollweideAxes\n\u001b[1;32m---> 57\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpolar\u001b[39;00m \u001b[39mimport\u001b[39;00m PolarAxes\n\u001b[0;32m     58\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmpl_toolkits\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmplot3d\u001b[39;00m \u001b[39mimport\u001b[39;00m Axes3D\n\u001b[0;32m     61\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mProjectionRegistry\u001b[39;00m:\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1138\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1078\u001b[0m, in \u001b[0;36m_find_spec\u001b[1;34m(name, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1504\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1476\u001b[0m, in \u001b[0;36m_get_spec\u001b[1;34m(cls, fullname, path, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:1612\u001b[0m, in \u001b[0;36mfind_spec\u001b[1;34m(self, fullname, target)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:147\u001b[0m, in \u001b[0;36m_path_stat\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run driver.py --dataset ../basic_series/raw_1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Setup ****\n",
      "Total params: 0.58k\n",
      "************\n",
      "AAL(\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "    (linear): Linear(in_features=1, out_features=1, bias=True)\n",
      "    (attentionLayer): AttentionLayer(\n",
      "      (Wq): Linear(in_features=1, out_features=8, bias=False)\n",
      "      (Wk): Linear(in_features=1, out_features=8, bias=False)\n",
      "      (Wv): Linear(in_features=1, out_features=1, bias=False)\n",
      "      (attention): Attention(\n",
      "        (dropout): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((1, 1), eps=1e-05, elementwise_affine=True)\n",
      "    (f): ELU(alpha=1.0)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "    (linear1): Linear(in_features=15, out_features=15, bias=True)\n",
      "    (attentionLayer): AttentionLayer(\n",
      "      (Wq): Linear(in_features=1, out_features=8, bias=False)\n",
      "      (Wk): Linear(in_features=1, out_features=8, bias=False)\n",
      "      (Wv): Linear(in_features=1, out_features=1, bias=False)\n",
      "      (attention): Attention(\n",
      "        (dropout): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((15, 1), eps=1e-05, elementwise_affine=True)\n",
      "    (EDAttention): Attention(\n",
      "      (dropout): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "    (norm2): LayerNorm((15, 1), eps=1e-05, elementwise_affine=True)\n",
      "    (linear2): Linear(in_features=15, out_features=15, bias=True)\n",
      "    (f): ELU(alpha=1.0)\n",
      "  )\n",
      ")\n",
      "********** Epoche 1 **********\n",
      "loss :  0.011365587823092937\n",
      "********** Epoche 101 **********\n",
      "loss :  0.00031794424285180867\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\OneDrive\\Escritorio\\STNN-main\\model\\driver.py:108\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[0;32m    105\u001b[0m \u001b[39m#==============================================================================\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39m#==============================================================================\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m model \u001b[39m=\u001b[39m train(model, train_loader,lr\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mlr, learning_rate_change\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mlr_decay, epoch_update\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mlr_update,\n\u001b[0;32m    109\u001b[0m             weight_decay\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mwd, num_epochs \u001b[39m=\u001b[39;49m args\u001b[39m.\u001b[39;49mepochs, gradclip\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mgradclip)\n\u001b[0;32m    110\u001b[0m \u001b[39m#******************************************************************************\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39m# Prediction\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39m#******************************************************************************\u001b[39;00m\n\u001b[0;32m    113\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\OneDrive\\Escritorio\\STNN-main\\model\\train.py:25\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, lr, epoch_update, learning_rate_change, weight_decay, num_epochs, gradclip)\u001b[0m\n\u001b[0;32m     23\u001b[0m Yt \u001b[39m=\u001b[39m Y[:,:,:,\u001b[39m0\u001b[39m:Y\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m]\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     24\u001b[0m \u001b[39m#loss\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m out \u001b[39m=\u001b[39m model(X,Yt)\n\u001b[0;32m     26\u001b[0m loss \u001b[39m=\u001b[39m criterion(out,Y)\n\u001b[0;32m     27\u001b[0m \u001b[39m# ===================backward====================\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\Escritorio\\STNN-main\\model\\model.py:124\u001b[0m, in \u001b[0;36mAAL.forward\u001b[1;34m(self, x_enc, x_dec)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x_enc, x_dec):\n\u001b[0;32m    123\u001b[0m     c \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x_enc)\n\u001b[1;32m--> 124\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(c, x_dec)\n\u001b[0;32m    126\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\Escritorio\\STNN-main\\model\\model.py:100\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, c, x)\u001b[0m\n\u001b[0;32m     97\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n\u001b[0;32m     99\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdy,\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 100\u001b[0m t,scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattentionLayer(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmask)\n\u001b[0;32m    101\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1(x \u001b[39m+\u001b[39m t)\n\u001b[0;32m    103\u001b[0m t,scores\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mEDAttention(x, c, c)\u001b[39m#(query y)(key,value x)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\Escritorio\\STNN-main\\model\\model.py:42\u001b[0m, in \u001b[0;36mAttentionLayer.forward\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     41\u001b[0m     q,k,v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mWq(x),\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mWk(x),\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mWv(x)\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(q, k, v, mask)\n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\OneDrive\\Escritorio\\STNN-main\\model\\model.py:22\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, q, k, v, mask)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, q, k, v, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> 22\u001b[0m     scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmatmul(q, k\u001b[39m.\u001b[39;49mtranspose(\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)) \u001b[39m/\u001b[39m math\u001b[39m.\u001b[39msqrt(q\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)) \u001b[39m#batch *batch(Q,K)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     scores \u001b[39m=\u001b[39m scores\u001b[39m.\u001b[39mmasked_fill(mask \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m scores  \n\u001b[0;32m     25\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mmatmul(scores, v),scores\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run driver.py --dataset ../basic_series/raw_12.csv --lr 0.2 --lr_decay 0.05  --dy 15 --noise 0.01 --length 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Setup ****\n",
      "Total params: 0.58k\n",
      "************\n",
      "AAL(\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "    (linear): Linear(in_features=1, out_features=1, bias=True)\n",
      "    (attentionLayer): AttentionLayer(\n",
      "      (Wq): Linear(in_features=1, out_features=8, bias=False)\n",
      "      (Wk): Linear(in_features=1, out_features=8, bias=False)\n",
      "      (Wv): Linear(in_features=1, out_features=1, bias=False)\n",
      "      (attention): Attention(\n",
      "        (dropout): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((1, 1), eps=1e-05, elementwise_affine=True)\n",
      "    (f): ELU(alpha=1.0)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (dropout): Dropout(p=0, inplace=False)\n",
      "    (linear1): Linear(in_features=15, out_features=15, bias=True)\n",
      "    (attentionLayer): AttentionLayer(\n",
      "      (Wq): Linear(in_features=1, out_features=8, bias=False)\n",
      "      (Wk): Linear(in_features=1, out_features=8, bias=False)\n",
      "      (Wv): Linear(in_features=1, out_features=1, bias=False)\n",
      "      (attention): Attention(\n",
      "        (dropout): Dropout(p=0, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm1): LayerNorm((15, 1), eps=1e-05, elementwise_affine=True)\n",
      "    (EDAttention): Attention(\n",
      "      (dropout): Dropout(p=0, inplace=False)\n",
      "    )\n",
      "    (norm2): LayerNorm((15, 1), eps=1e-05, elementwise_affine=True)\n",
      "    (linear2): Linear(in_features=15, out_features=15, bias=True)\n",
      "    (f): ELU(alpha=1.0)\n",
      "  )\n",
      ")\n",
      "********** Epoche 1 **********\n",
      "loss :  0.004402314778417349\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\Desktop\\STNN-main\\model\\driver.py:108\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[0;32m    105\u001b[0m \u001b[39m#==============================================================================\u001b[39;00m\n\u001b[0;32m    106\u001b[0m \u001b[39m# Start training\u001b[39;00m\n\u001b[0;32m    107\u001b[0m \u001b[39m#==============================================================================\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m model \u001b[39m=\u001b[39m train(model, train_loader,lr\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mlr, learning_rate_change\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mlr_decay, epoch_update\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mlr_update,\n\u001b[0;32m    109\u001b[0m             weight_decay\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mwd, num_epochs \u001b[39m=\u001b[39;49m args\u001b[39m.\u001b[39;49mepochs, gradclip\u001b[39m=\u001b[39;49margs\u001b[39m.\u001b[39;49mgradclip)\n\u001b[0;32m    110\u001b[0m \u001b[39m#******************************************************************************\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[39m# Prediction\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[39m#******************************************************************************\u001b[39;00m\n\u001b[0;32m    113\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\Desktop\\STNN-main\\model\\train.py:31\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, lr, epoch_update, learning_rate_change, weight_decay, num_epochs, gradclip)\u001b[0m\n\u001b[0;32m     29\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m     30\u001b[0m     torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), gradclip)\n\u001b[1;32m---> 31\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     32\u001b[0m \u001b[39m# schedule learning rate decay    \u001b[39;00m\n\u001b[0;32m     33\u001b[0m lr_scheduler(optimizer, epoch, lr_decay_rate\u001b[39m=\u001b[39mlearning_rate_change, decayEpoch\u001b[39m=\u001b[39mepoch_update)                \n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adamw.py:171\u001b[0m, in \u001b[0;36mAdamW.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    158\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    160\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[0;32m    161\u001b[0m         group,\n\u001b[0;32m    162\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    168\u001b[0m         state_steps,\n\u001b[0;32m    169\u001b[0m     )\n\u001b[1;32m--> 171\u001b[0m     adamw(\n\u001b[0;32m    172\u001b[0m         params_with_grad,\n\u001b[0;32m    173\u001b[0m         grads,\n\u001b[0;32m    174\u001b[0m         exp_avgs,\n\u001b[0;32m    175\u001b[0m         exp_avg_sqs,\n\u001b[0;32m    176\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    177\u001b[0m         state_steps,\n\u001b[0;32m    178\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    179\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    180\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    181\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    182\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    183\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    184\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    185\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    186\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    187\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    188\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m    189\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    190\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m    191\u001b[0m     )\n\u001b[0;32m    193\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adamw.py:321\u001b[0m, in \u001b[0;36madamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    319\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[1;32m--> 321\u001b[0m func(\n\u001b[0;32m    322\u001b[0m     params,\n\u001b[0;32m    323\u001b[0m     grads,\n\u001b[0;32m    324\u001b[0m     exp_avgs,\n\u001b[0;32m    325\u001b[0m     exp_avg_sqs,\n\u001b[0;32m    326\u001b[0m     max_exp_avg_sqs,\n\u001b[0;32m    327\u001b[0m     state_steps,\n\u001b[0;32m    328\u001b[0m     amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    329\u001b[0m     beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    330\u001b[0m     beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    331\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    332\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    333\u001b[0m     eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    334\u001b[0m     maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    335\u001b[0m     capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[0;32m    336\u001b[0m     differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[0;32m    337\u001b[0m     grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[0;32m    338\u001b[0m     found_inf\u001b[39m=\u001b[39;49mfound_inf,\n\u001b[0;32m    339\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\adamw.py:440\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    438\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m    439\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 440\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39;49m bias_correction2_sqrt)\u001b[39m.\u001b[39;49madd_(eps)\n\u001b[0;32m    442\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corridas = [\n",
    "    \"run driver.py --dataset ../basic_series/raw_1.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_2.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_3.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_4.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_5.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_6.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_7.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_8.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_9.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_10.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_11.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_12.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_13.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_14.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_15.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_16.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_17.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_18.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_19.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_20.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\",\n",
    "    \"run driver.py --dataset ../basic_series/raw_21.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'run driver.py --dataset ../basic_series/raw_1.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Juan Pablo\\Desktop\\STNN-main\\model\\run.ipynb Cell 8\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Juan%20Pablo/Desktop/STNN-main/model/run.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Define the list of Python scripts to execute\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Juan%20Pablo/Desktop/STNN-main/model/run.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Execute each script using a for loop\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Juan%20Pablo/Desktop/STNN-main/model/run.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m script_filename \u001b[39min\u001b[39;00m corridas :\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Juan%20Pablo/Desktop/STNN-main/model/run.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# Construct the full command\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Juan%20Pablo/Desktop/STNN-main/model/run.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Juan%20Pablo/Desktop/STNN-main/model/run.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39m# Execute the script\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Juan%20Pablo/Desktop/STNN-main/model/run.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     subprocess\u001b[39m.\u001b[39;49mrun(script_filename, shell\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Juan Pablo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m     retcode \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mpoll()\n\u001b[0;32m    570\u001b[0m     \u001b[39mif\u001b[39;00m check \u001b[39mand\u001b[39;00m retcode:\n\u001b[1;32m--> 571\u001b[0m         \u001b[39mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[39m.\u001b[39margs,\n\u001b[0;32m    572\u001b[0m                                  output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr)\n\u001b[0;32m    573\u001b[0m \u001b[39mreturn\u001b[39;00m CompletedProcess(process\u001b[39m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command 'run driver.py --dataset ../basic_series/raw_1.csv --lr 0.2 --lr_decay 0.05 --dy 15 --noise 0.01 --length 8' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the list of Python scripts to execute\n",
    "# Execute each script using a for loop\n",
    "for script_filename in corridas :\n",
    "    # Construct the full command\n",
    "    \n",
    "    # Execute the script\n",
    "    subprocess.run(script_filename, shell=True, check=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
